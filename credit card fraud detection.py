# -*- coding: utf-8 -*-
"""DS_Project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1XzsjSEtKrF2cxQ84RHbsPNveDBJ7w2YU

<a href="https://colab.research.google.com/github/Suhrad/Credit-Card-Fraud-Detection/blob/main/DS_Project.ipynb" target="_parent"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a>

Importing libraries
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np 
import pandas as pd 
import matplotlib.pyplot as plt 
import seaborn as sns; sns.set()

from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, roc_auc_score, roc_curve

from imblearn.under_sampling import RandomUnderSampler

from IPython.display import Image  
from sklearn.tree import export_graphviz
import pydotplus

# %matplotlib inline

"""Importing CSV file"""

from google.colab import drive
drive.mount('/content/drive')

data = pd.read_csv("/content/drive/My Drive/DS Project/creditcard.csv")
data

print(data.shape)

data.head()

data.describe()

"""Finding the percentage of Fraud transtistions"""

fraud = data[data['Class'] == 1] 
valid = data[data['Class'] == 0] 
outlierFraction = len(fraud)/float(len(valid)) 
outlierFraction

"""Finding the number of missing data"""

print('Number of missing data:', fraud.isnull().sum().max())

"""Basic statistical details"""

fraud

valid

"""Number of fraud and valid transactions"""

print('Fraud Cases: {}'.format(len(data[data['Class'] == 1]))) 
print('Valid Transactions: {}'.format(len(data[data['Class'] == 0])))

"""**Visualize the discrepancy in our dataset.**"""

fig, ax = plt.subplots(figsize=(6, 4))

ax = sns.countplot(x='Class', data=data)
plt.tight_layout()

fraudamount=fraud.Amount.describe() 
fraudamount

validamount=valid.Amount.describe() 
validamount

fig, ax = plt.subplots(nrows=2, ncols=1, figsize=(10, 7))

ax[0].hist(data['Time'][data['Class'] == 0], bins=40)
ax[0].set_title('Regular Transactions', fontsize=14)
ax[0].set_ylabel('Transactions')

ax[1].hist(data['Time'][data['Class'] == 1], bins=40)
ax[1].set_title('Fraudulent Transactions', fontsize=14)
ax[1].set_ylabel('Transactions')
ax[1].set_xlabel('Time (seconds)')

fig, ax = plt.subplots(nrows=2, ncols=1, figsize=(10, 7))

ax[0].hist(data['Amount'][data['Class'] == 0], bins=20)
ax[0].set_title('Regular Transactions', fontsize=14)
ax[0].set_ylabel('Transactions')

ax[1].hist(data['Amount'][data['Class'] == 1], bins=20)
ax[1].set_title('Fraudulent Transactions', fontsize=14)
ax[1].set_ylabel('Transactions')
ax[1].set_xlabel('Amount')

corr = data.corr()
fig, ax = plt.subplots(figsize=(9, 7))

sns.heatmap(corr, xticklabels=corr.columns, yticklabels=corr.columns,
            linewidths=.1, cmap="RdBu", ax=ax)
plt.tight_layout()

data_clean = data.copy()

scaler = StandardScaler()
data_clean['std_amount'] = scaler.fit_transform(data_clean['Amount'].values.reshape(-1, 1))
data_clean['std_time'] = scaler.fit_transform(data_clean['Time'].values.reshape(-1, 1))

data_clean.drop(['Amount', 'Time'], axis=1, inplace=True)

data_clean.head()

X = data_clean.drop('Class', axis=1)
y = data_clean['Class']

X_train, X_test, y_train, y_test = train_test_split(X, y)

rus = RandomUnderSampler()
X_rus, y_rus = rus.fit_sample(X_train, y_train)

print(pd.Series(y_rus).value_counts())

fig, ax = plt.subplots(figsize=(7, 4))
ax = sns.countplot(y_rus)
plt.tight_layout()

corr_rus = pd.DataFrame(X_rus).corr()

fig, ax = plt.subplots(figsize=(9, 7))

sns.heatmap(corr_rus, xticklabels=corr.columns, yticklabels=corr.columns,
            linewidths=.1, cmap="RdBu", ax=ax)
plt.tight_layout()

model_log = LogisticRegression()

model_log.fit(X_rus, y_rus)

y_pred_log = model_log.predict(X_test)

print(classification_report(y_test, y_pred_log))

print("AUC: {:.2f}\n".format(roc_auc_score(y_test, y_pred_log)))

fig, ax = plt.subplots()
sns.heatmap(confusion_matrix(y_test, y_pred_log, normalize='true'), annot=True, ax=ax)

ax.set_title("Confusion Matrix")
ax.set_ylabel("Real Value")
ax.set_xlabel("Predicted")

plt.show()